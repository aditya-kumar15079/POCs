2025-03-27 15:25:27,969 - llm_judge - INFO - Logger initialized
2025-03-27 15:25:27,969 - llm_judge - INFO - Initialized Azure OpenAI client with deployment: gpt-4o-mini
2025-03-27 15:25:27,969 - llm_judge - INFO - LLM Judge initialized successfully
2025-03-27 15:25:27,969 - llm_judge - INFO - Starting LLM Judge evaluation
2025-03-27 15:25:28,377 - llm_judge - INFO - No metrics configuration found in Excel: Worksheet named 'Metrics' not found
2025-03-27 15:25:28,377 - llm_judge - INFO - Processing test case QA1
2025-03-27 15:25:28,377 - llm_judge - INFO - Evaluating Accuracy for prompt: What types of expenses are not reimbursed by the c...
2025-03-27 15:25:28,440 - llm_judge - INFO - Evaluating Coherence for prompt: What types of expenses are not reimbursed by the c...
2025-03-27 15:25:28,440 - llm_judge - INFO - Evaluating Relevance for prompt: What types of expenses are not reimbursed by the c...
2025-03-27 15:25:28,455 - llm_judge - INFO - Evaluating Faithfulness for prompt: What types of expenses are not reimbursed by the c...
2025-03-27 15:25:28,455 - llm_judge - INFO - Evaluating Bias for prompt: What types of expenses are not reimbursed by the c...
2025-03-27 15:25:28,455 - llm_judge - INFO - Evaluating Toxicity for prompt: What types of expenses are not reimbursed by the c...
2025-03-27 15:25:31,107 - llm_judge - INFO - Toxicity evaluation score: 100
2025-03-27 15:25:31,107 - llm_judge - INFO - Bias evaluation score: 90
2025-03-27 15:25:31,500 - llm_judge - INFO - Faithfulness evaluation score: 85
2025-03-27 15:25:31,610 - llm_judge - INFO - Relevance evaluation score: 95
2025-03-27 15:25:31,689 - llm_judge - INFO - Accuracy evaluation score: 90
2025-03-27 15:25:31,987 - llm_judge - INFO - Coherence evaluation score: 85
2025-03-27 15:25:31,987 - llm_judge - INFO - Processing test case QA2
2025-03-27 15:25:31,987 - llm_judge - INFO - Evaluating Accuracy for prompt: Under what conditions will MCUL & CUSG reimburse s...
2025-03-27 15:25:32,003 - llm_judge - INFO - Evaluating Coherence for prompt: Under what conditions will MCUL & CUSG reimburse s...
2025-03-27 15:25:32,003 - llm_judge - INFO - Evaluating Relevance for prompt: Under what conditions will MCUL & CUSG reimburse s...
2025-03-27 15:25:32,003 - llm_judge - INFO - Evaluating Faithfulness for prompt: Under what conditions will MCUL & CUSG reimburse s...
2025-03-27 15:25:32,003 - llm_judge - INFO - Evaluating Bias for prompt: Under what conditions will MCUL & CUSG reimburse s...
2025-03-27 15:25:32,003 - llm_judge - INFO - Evaluating Toxicity for prompt: Under what conditions will MCUL & CUSG reimburse s...
2025-03-27 15:25:34,219 - llm_judge - INFO - Toxicity evaluation score: 95
2025-03-27 15:25:34,361 - llm_judge - INFO - Bias evaluation score: 90
2025-03-27 15:25:34,392 - llm_judge - INFO - Accuracy evaluation score: 95
2025-03-27 15:25:34,912 - llm_judge - INFO - Coherence evaluation score: 85
2025-03-27 15:25:34,959 - llm_judge - INFO - Faithfulness evaluation score: 90
